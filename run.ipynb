{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YjiqmMFEanc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0i2q_i0Y-ljE"},"outputs":[],"source":["!pip install fastmri"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3430,"status":"ok","timestamp":1652574786895,"user":{"displayName":"Rohit Kumar","userId":"03125809965765866405"},"user_tz":240},"id":"2wUodLWM-poB"},"outputs":[],"source":["import os\n","import h5py\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from scipy.ndimage import zoom\n","import fastmri\n","import torch\n","from fastmri.data import transforms as T\n","from fastmri.data.subsample import RandomMaskFunc\n","import pywt\n","import warnings\n","from PIL import Image\n","from IPython import display"]},{"cell_type":"markdown","metadata":{"id":"pMsu38KcvgSt"},"source":["## Data util functions"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1652574829491,"user":{"displayName":"Rohit Kumar","userId":"03125809965765866405"},"user_tz":240},"id":"zfLU07Xq_Ejl"},"outputs":[],"source":["def data_GT(path):\n","  '''\n","  Load Ground truth kspace and images of all slices from given path\n","  '''\n","  data = dict()\n","  data['kspace'] = []\n","\n","  volumes = []\n","  for file in os.listdir(path):\n","    file_name = os.path.join(path, file)\n","    hf = h5py.File(file_name)\n","    volume_kspace = hf['kspace'][()]\n","    data['kspace'].append(volume_kspace)\n","    vol, _, _ = volume_kspace.shape\n","    volumes.append(vol)\n","\n","\n","  data['slice_img'] = []\n","  for i in range(len(data['kspace'])):\n","        \n","    slice_kspace2 = T.to_tensor(data['kspace'][i])      # Convert from numpy array to pytorch tensor\n","    slice_image = fastmri.ifft2c(slice_kspace2)           # Apply Inverse Fourier Transform to get the complex image\n","\n","    slice_image_abs = fastmri.complex_abs(slice_image)   # Compute absolute value to get a real image\n","    data['slice_img'].append(slice_image_abs)\n","\n","  return data"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1652574832210,"user":{"displayName":"Rohit Kumar","userId":"03125809965765866405"},"user_tz":240},"id":"3lq6p_SEAFqB"},"outputs":[],"source":["def subsample_data(dataGT):\n","  '''\n","  downsampling/compressed sensing the data by multiplying with mask\n","  '''\n","  mask_func = RandomMaskFunc(center_fractions=[0.04], accelerations=[4])  # Create the mask function object\n","  masked_kspace, mask = T.apply_mask(torch.tensor(dataGT['kspace'][0]), mask_func)   # Apply the mask to k-space\n","  #%%\n","  dataGT['masked_img'] = []\n","  dataGT['masked_kspace'] = []\n","  for i in range(len(dataGT['kspace'])):\n","        \n","    slice_kspace2 = T.to_tensor(dataGT['kspace'][i])      # Convert from numpy array to pytorch tensor\n","    \n","    mask_func = RandomMaskFunc(center_fractions=[0.04], accelerations=[4])  # Create the mask function object\n","    masked_kspace, mask = T.apply_mask(slice_kspace2, mask_func)   # Apply the mask to k-space\n","    dataGT['masked_kspace'].append(masked_kspace)\n","    slice_image = fastmri.ifft2c(masked_kspace)           # Apply Inverse Fourier Transform to get the complex image\n","    slice_image_abs = fastmri.complex_abs(slice_image)   # Compute absolute value to get a real image\n","    dataGT['masked_img'].append(slice_image_abs)\n","\n","    return dataGT, mask"]},{"cell_type":"markdown","metadata":{"id":"vJVwAfINvteN"},"source":["# **Objective function** "]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":291,"status":"ok","timestamp":1652574838438,"user":{"displayName":"Rohit Kumar","userId":"03125809965765866405"},"user_tz":240},"id":"0zDC2bwBuYqH"},"outputs":[],"source":["from scipy.fftpack import dct, idct\n","from scipy.optimize import minimize\n","\n","def TV(img, weight):      \n","    tv_h = ((img[1:,:] - img[:-1,:])**2).sum()\n","    tv_w = ((img[:,1:] - img[:,:-1])**2).sum()    \n","    return weight * (tv_h + tv_w)\n","\n","\n","def obj_fn(x, y, u, l):\n","  #error constraint\n","  #print(x.shape, y.shape, u.shape, l)\n","  x = x.reshape(y.shape)\n","  term1 = np.linalg.norm(np.fft.fftshift(np.fft.fft2(x)) * u - y)**2\n","  \n","  #l1 constraint\n","  term2 = np.linalg.norm(dct(dct(x.T, norm='ortho').T, norm='ortho'), ord=1)\n","  #regularizer\n","\n","  return term1+l*term2\n","\n","def obj_fnTV(x, y, u, l1, l2=0.1):\n","  #error constraint\n","  #print(x.shape, y.shape, u.shape, l)\n","  x = x.reshape(y.shape)\n","  term1 = np.linalg.norm(np.fft.fftshift(np.fft.fft2(x)) * u - y)**2\n","  \n","  #l1 constraint\n","  term2 = np.linalg.norm(dct(dct(x.T, norm='ortho').T, norm='ortho'), ord=1)\n","  #regularizer\n","\n","  return term1+l1*term2+l2*TV(x, l2)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":238,"status":"ok","timestamp":1652574841504,"user":{"displayName":"Rohit Kumar","userId":"03125809965765866405"},"user_tz":240},"id":"i7ZTrWAz9V0L"},"outputs":[],"source":["def PSNR(original, compressed):\n","    mse = np.mean((original - compressed) ** 2)\n","    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n","                 \n","        return 100\n","    max_pixel = 1.0\n","    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n","    return psnr"]},{"cell_type":"markdown","metadata":{"id":"-kTdALlSvmC0"},"source":["## Load data"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"V2WXoI9V-2HF"},"outputs":[{"name":"stdout","output_type":"stream","text":["(35, 640, 368) complex64\n","torch.Size([35, 640, 368]) torch.float32\n"]}],"source":["\n","path = \"data/\"\n","\n","data = data_GT(path)\n","print(data['kspace'][0].shape, data['kspace'][0].dtype)\n","print(data['slice_img'][0].shape, data['slice_img'][0].dtype)\n","dataCS, U = subsample_data(data)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1651157712667,"user":{"displayName":"Deeksha Shama","userId":"09404625956223372882"},"user_tz":240},"id":"HuRoIqwsWh3w","outputId":"066b78fe-f48d-4ec1-f49d-f65742f0c371"},"outputs":[{"name":"stdout","output_type":"stream","text":["(35, 640, 368) (35, 640, 368)\n","(640, 368) (640, 368)\n"]}],"source":["xtrue_vol = np.array(dataCS['slice_img'][0])\n","y_vol = np.array(dataCS['masked_kspace'][0][:,:, :, 0]) + 1j* np.array(dataCS['masked_kspace'][0][:,:, :, 1])\n","print(xtrue_vol.shape, y_vol.shape)\n","\n","#choose one 2d slice for experimentation\n","\n","xtrue = xtrue_vol[15]   #.reshape(-1,1)\n","y = y_vol[15]    #.reshape(-1, 1)\n","u = U[0, 0, :, 0].numpy()\n","print(xtrue.shape, y.shape)"]},{"cell_type":"markdown","metadata":{"id":"EWyuGMf-xzEf"},"source":["## Generate mask U"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ZUo9M0EmESiB"},"outputs":[],"source":["psize = 16\n","S = int(psize//(10)) #10% sparse\n","q = np.random.permutation(psize)\n","patch_u = np.zeros(psize)\n","patch_u[q[:S]] = 1"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Au6K6Z5Zo_fm"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["mat = np.repeat(patch_u.reshape(-1,1), 16, 1)\n","plt.imshow(mat.T)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Jt2BtFfNwh4s"},"source":["# Patchwise reconstruction with NL-CGD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8gJZTZsCt9A9"},"outputs":[],"source":["#choose one 2d slice for experimentation\n","xtrue_vol = np.array(dataCS['slice_img'][0])\n","\n","xtrue = xtrue_vol[15]   #.reshape(-1,1)\n","R, C = xtrue.shape\n","#30% sparse\n","S = int(psize//(10))\n","q = np.random.permutation(psize)\n","patch_u = np.zeros(psize)\n","patch_u[q[:S]] = 1\n","lamda = 0.1\n","\n","#xmin = xtrue.min()\n","#xmax = xtrue.max()\n","#xtrue = (xtrue-xmin)/(xmax-xmin)\n","xpred = np.zeros((R, C))\n","x_under = np.zeros((R, C))\n","for i in range(0,R, psize ):\n","  for j in range(0, C, psize):\n","    patch_x = xtrue[i:i+psize, j:j+psize] #extract patch\n","    xmin = patch_x.min()\n","    xmax = patch_x.max()\n","    patch_x = (patch_x-xmin)/(xmax-xmin) #normalize\n","    patch_y = patch_u*np.fft.fftshift(np.fft.fft2(patch_x))\n","    \n","    x_under[i:i+psize, j:j+psize] = np.real(np.fft.ifft2(np.fft.ifftshift(patch_y))) * (xmax-xmin) + xmin #naive reconstrcution with IFFT\n","\n","    x0 = np.zeros((psize, psize))\n","    min_result = minimize(obj_fnTV, x0,  args = ( patch_y,patch_u, lamda), method='CG', options={'maxiter' : 250})   #NLCGD step\n","\n","    patch_pred = min_result['x'].reshape(psize, psize)    \n","    \n","    if j==0:\n","      print(i/psize, j/psize, min_result[\"success\"], obj_fnTV(x0, patch_y, patch_u, lamda), obj_fn(patch_pred, patch_y, patch_u, lamda) )\n","    patch_pred = patch_pred*(xmax-xmin) + xmin\n","    xpred[i:i+psize, j:j+psize] = patch_pred \n","  \n","#xpred = x_pred*(xmax-xmin) + xmin\n","print('Error between GT and Recon = ', np.linalg.norm(xpred-xtrue)**2, 'PSNR = ', PSNR(xtrue, xpred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pqlGrw2grSAc"},"outputs":[],"source":["#visualize results\n","f, ax = plt.subplots(1,3, figsize=(10,5))\n","ax[0].imshow(xtrue)\n","ax[0].set_title(\"ground truth\")\n","ax[1].imshow(x_under)\n","ax[1].set_title(\"undersampled IFFT\")\n","ax[2].imshow(xpred)\n","ax[2].set_title(\"reconstruction\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrZl4WS4q1Re"},"outputs":[],"source":["xtrue = (xtrue - xtrue.min())/(xtrue.max() - xtrue.min())\n","xpred = (xpred - xpred.min())/(xpred.max() - xpred.min())\n","print('Error between GT and Recon = ',np.mean((xpred-xtrue)**2), 'PSNR = ', PSNR(xtrue*255, xpred*255))"]},{"cell_type":"markdown","metadata":{"id":"03-d5fECWCYS"},"source":["# Trial experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OB4KhIquWSDc"},"outputs":[],"source":["psize = 16\n","x = np.random.randn(psize,psize)\n","x = (x - np.min(x))/(np.max(x) - np.min(x))\n","u = np.sign(np.random.randn(psize))\n","u[u<0] = 0\n","xfft = np.fft.fftshift(np.fft.fft2(x))\n","y = u*xfft\n","\n","'''\n","plt.imshow(x)\n","plt.colorbar()\n","plt.show()\n","\n","\n","plt.stem(u)\n","plt.show()\n","\n","\n","plt.imshow(np.abs(xfft))\n","plt.colorbar()\n","plt.show()\n","\n","\n","plt.imshow(np.abs(y))\n","plt.colorbar()\n","plt.show()\n","'''\n","lamda = 0.1\n","print(\"Least attainable value of obj func = \",  obj_fn(x, y, u, lamda))\n","min_result = minimize(obj_fn, x0,  args = ( y, u, lamda), method='CG', options={'maxiter' : 1000})\n","xpred = min_result['x'].reshape(psize, psize)\n","print('Reconstruction success: ', min_result['success'], 'Final value of obj func = ', obj_fn(xpred, y, u, lamda))\n","print('Error between GT and Recon = ', np.linalg.norm(xpred-x)**2)"]},{"cell_type":"markdown","metadata":{"id":"xrsjbJKKBOtN"},"source":["# Implementation of soft thresholding\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"2YXmtOFXBik0"},"outputs":[],"source":["def SoftThresh(y, t):\n","    x_hat = (y / np.abs(y)) * np.maximum(np.abs(y)-t, 0)\n","    return x_hat"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CxB5oCCf_6rL"},"outputs":[],"source":["x_norm = (xtrue - xtrue.min())/(xtrue.max() - xtrue.min()) #normalise the image"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Ms2EP48uBaNe"},"outputs":[],"source":["mri_fourier_n = np.fft.fft2(x_norm) # 2D Fourier transform (=data acquired in practice)\n","mri_fourier_shift_n = np.fft.fftshift(mri_fourier_n) # Centering zero coordinates\n","mri_fourier_powerspect_n = np.abs(mri_fourier_shift_n) ** 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w94rMExwBeK8"},"outputs":[],"source":["fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","ax[0].imshow(x_norm)\n","ax[0].set_title('original')\n","ax[1].imshow(np.log10(mri_fourier_powerspect_n.real))\n","ax[1].set_title('k-space power spectrum')\n","ax[2].imshow(np.fft.ifft2(mri_fourier_n).real)\n","ax[2].set_title('Fourier inverse');\n","\n","error = np.abs(np.linalg.norm(x_norm) - np.linalg.norm(np.fft.ifft2(mri_fourier_shift_n))) / np.linalg.norm(x_norm)\n","print('Reconstruction error: ', error)"]},{"cell_type":"markdown","metadata":{"id":"e-nqddmUDHxE"},"source":["# pISTA with Random Mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GvR8AUuiBlOH"},"outputs":[],"source":["l = 0.0436 # chosen through grid search\n","n_iter = 100\n","\n","mri_under = np.zeros(mri_fourier_n.shape, dtype='complex')\n","\n","p = 0.70 # Percentage of coefficients kept\n","np.random.seed(42)\n","mask = np.random.binomial(1, p, size=mri_fourier_n.shape[1]).astype(np.bool)\n","mri_under[:,mask] = mri_fourier_shift_n[:,mask]\n","mri_under = np.fft.ifftshift(mri_under)\n","mri_rec = np.fft.ifft2(mri_under)\n","\n","fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","ax[0].imshow(mri_rec.real)\n","ax[0].set_title('Undersample signal')\n","ax[2].imshow(xtrue)\n","ax[2].set_title('original MRI')\n","\n","\n","Y = mri_under\n","Xi = Y\n","Xi_rec = np.zeros_like(Xi)\n","\n","for i in range(n_iter):    \n","    xi = np.fft.ifft2(Xi)\n","    xi_st = SoftThresh(xi.real, l)\n","    Xi = np.fft.fft2(xi_st)\n","    Xi = Xi * (Y==0) + Y\n","\n","    ax[1].imshow(xi.real)\n","    ax[1].set_title('iteration %d' % i)\n","    display.display(plt.gcf())\n","    display.clear_output(wait=True)\n","\n","\n","error = np.abs(np.linalg.norm(xtrue_n) - np.linalg.norm(xi)) / np.linalg.norm(xtrue_n)\n","print('Reconstruction error: ', error) # 0.026545458298253805"]},{"cell_type":"markdown","metadata":{"id":"UnDOZufsDQSB"},"source":["# pISTA with gaussian Mask(15% sample from K-Space)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84aYlpPjHSX7"},"outputs":[],"source":["# Filtre gaussien 2D\n","\n","def gaussian_2d(x,y,mx,my,sx,sy):\n","    f_xy = (1/np.sqrt( 2.0 * sx**2))*(np.exp(-((x-mx)**2)/(2 * sx**2))) * (1/np.sqrt( 2.0 * sy**2))*(np.exp(-((y-my)**2)/(2 * sy**2)))\n","    return f_xy\n","\n","x_l = (np.linspace(-1,1,368)) # define the x,y range\n","y_l = (np.linspace(-1,1,640)) \n","x, y = np.meshgrid(x_l, y_l)\n","g = gaussian_2d(x,y,0,0,0.2,0.2) # see the varince control the shape of the mask\n","\n","# Mask to sample according to the Gaussian filter\n","np.random.seed(42)\n","P = 0.15 ## define percentage of undersampling\n","N = int(P * (640*368)) # outoff all these elements these many elements have to be selected\n","result = np.zeros((640,368))\n","ia = np.arange(result.size)\n","tw = float(np.sum(g.ravel()))\n","result.ravel()[np.random.choice(ia, p=g.ravel()/tw, size=N, replace=False)]=1\n","plt.imshow(result, cmap='gray')\n","plt.title('Sampling mask with P=%f' % P)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOenE2aqDs6a"},"outputs":[],"source":["mri_under = mri_fourier_shift_n * result\n","mri_under = np.fft.ifftshift(mri_under)\n","mri_rec = np.fft.ifft2(mri_under)\n","\n","fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","ax[0].imshow(mri_rec.real)\n","ax[0].set_title('Undersampled signal')\n","ax[2].imshow(np.array(x_norm))\n","ax[2].set_title('original')\n","\n","Y = mri_under\n","Xi = Y\n","n_iter = 100\n","\n","for i in range(n_iter):    \n","    xi = np.fft.ifft2(Xi)\n","    xi_st = SoftThresh(xi.real, 0.037)\n","    Xi = np.fft.fft2(xi_st)\n","    Xi = Xi * (Y==0) + Y\n","\n","    ax[1].imshow(xi.real)\n","    ax[1].set_title('Iteration %d' % i)\n","    display.display(plt.gcf())\n","    display.clear_output(wait=True)\n","\n","error = np.abs(np.linalg.norm(x_norm) - np.linalg.norm(xi)) / np.linalg.norm(x_norm)\n","print('Reconstruction error: ', error)  # 0.01839417469960822"]},{"cell_type":"markdown","metadata":{"id":"dxuBeUXPp-1J"},"source":["# pFISTA with random mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1PxHxWjip-Kk"},"outputs":[],"source":["mri_under = mri_fourier_shift_n * result\n","mri_under = np.fft.ifftshift(mri_under)\n","mri_rec = np.fft.ifft2(mri_under)\n","\n","fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","ax[0].imshow(mri_rec.real)\n","ax[0].set_title('Undersampled signal')\n","ax[2].imshow(np.array(x_norm))\n","ax[2].set_title('original')\n","\n","Y = mri_under\n","Xi_cap = Y\n","n_iter = 100\n","t = 1\n","\n","for i in range(n_iter):\n","    Xi_old = Xi.copy()    \n","    xi = np.fft.ifft2(Xi)\n","    xi_st = SoftThresh(xi.real, 0.037)\n","    Xi = np.fft.fft2(xi_st)\n","    t_n = (1+np.sqrt(1+(4*(t**2))))/2\n","    Xi_cap = Xi + (t/t_n)*(Xi - Xi_old)\n","    t = t_n.copy()\n","    Xi = Xi_cap * (Y==0) + Y\n","\n","    ax[1].imshow(xi.real)\n","    ax[1].set_title('iteraton %d' % i)\n","    display.display(plt.gcf())\n","    display.clear_output(wait=True)\n","\n","error = np.abs(np.linalg.norm(x_norm) - np.linalg.norm(xi)) / np.linalg.norm(x_norm)\n","print('Reconstruction error: ', error)  # 0.017587095652622363"]},{"cell_type":"markdown","metadata":{"id":"oriFUN6t0pq1"},"source":["# Gussian mask(5% sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HCwsJqqr0tb4"},"outputs":[],"source":["# Filtre gaussien 2D\n","\n","def gaussian_2d(x,y,mx,my,sx,sy):\n","    f_xy = (1/np.sqrt( 2.0 * sx**2))*(np.exp(-((x-mx)**2)/(2 * sx**2))) * (1/np.sqrt( 2.0 * sy**2))*(np.exp(-((y-my)**2)/(2 * sy**2)))\n","    return f_xy\n","\n","x_l = (np.linspace(-1,1,368)) # define the x,y range\n","y_l = (np.linspace(-1,1,640)) # TODO: to make this thing more general\n","x, y = np.meshgrid(x_l, y_l)\n","g = gaussian_2d(x,y,0,0,0.2,0.2) # see the varince control the shape of the mask\n","\n","# Mask to sample according to the Gaussian filter\n","np.random.seed(42)\n","P = 0.05 ## define percentage of undersampling\n","N = int(P * (640*368)) # outoff all these elements these many elements have to be selected\n","result = np.zeros((640,368))\n","ia = np.arange(result.size)\n","tw = float(np.sum(g.ravel()))\n","result.ravel()[np.random.choice(ia, p=g.ravel()/tw, size=N, replace=False)]=1\n","plt.imshow(result, cmap='gray')\n","plt.title('Sampling mask with P=%f' % P)"]},{"cell_type":"markdown","metadata":{"id":"kSeTYISK18FJ"},"source":["# pISTA perf. 5% sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NdUPnBXA016H"},"outputs":[],"source":["mri_under = mri_fourier_shift_n * result\n","mri_under = np.fft.ifftshift(mri_under)\n","mri_rec = np.fft.ifft2(mri_under)\n","\n","fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","ax[0].imshow(mri_rec.real)\n","ax[0].set_title('Undersampled signal')\n","ax[2].imshow(np.array(x_norm))\n","ax[2].set_title('original')\n","\n","Y = mri_under\n","Xi = Y\n","n_iter = 100\n","\n","for i in range(n_iter):    \n","    xi = np.fft.ifft2(Xi)\n","    xi_st = SoftThresh(xi.real, 0.037)\n","    Xi = np.fft.fft2(xi_st)\n","    Xi = Xi * (Y==0) + Y\n","\n","    ax[1].imshow(xi.real)\n","    ax[1].set_title('Itération %d' % i)\n","    display.display(plt.gcf())\n","    display.clear_output(wait=True)\n","\n","error = np.abs(np.linalg.norm(x_norm) - np.linalg.norm(xi)) / np.linalg.norm(x_norm)\n","print('Reconstruction error: ', error) # 0.02246191066455037"]},{"cell_type":"markdown","metadata":{},"source":["# pFISTA perf. 5% sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Tlf9pcD04_V"},"outputs":[],"source":["mri_under = mri_fourier_shift_n * result\n","mri_under = np.fft.ifftshift(mri_under)\n","mri_rec = np.fft.ifft2(mri_under)\n","\n","fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","ax[0].imshow(mri_rec.real)\n","ax[0].set_title('Undersampled signal')\n","ax[2].imshow(np.array(x_norm))\n","ax[2].set_title('original')\n","\n","Y = mri_under\n","Xi_cap = Y\n","n_iter = 100\n","t = 1\n","\n","for i in range(n_iter):\n","    Xi_old = Xi.copy()    \n","    xi = np.fft.ifft2(Xi)\n","    xi_st = SoftThresh(xi.real, 0.037)\n","    Xi = np.fft.fft2(xi_st)\n","    t_n = (1+np.sqrt(1+(4*(t**2))))/2\n","    Xi_cap = Xi + (t/t_n)*(Xi - Xi_old)\n","    t = t_n.copy()\n","    Xi = Xi_cap * (Y==0) + Y\n","\n","    ax[1].imshow(xi.real)\n","    ax[1].set_title('iteration %d' % i)\n","    display.display(plt.gcf())\n","    display.clear_output(wait=True)\n","\n","error = np.abs(np.linalg.norm(x_norm) - np.linalg.norm(xi)) / np.linalg.norm(x_norm)\n","print('Reconstruction error: ', error) # 0.018366764219697285"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"tradCS_recon.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
